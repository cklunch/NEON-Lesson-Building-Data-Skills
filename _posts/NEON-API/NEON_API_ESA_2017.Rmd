---
layout: post
title: "Using the NEON API in R"
description: "Tutorial for getting data from the NEON API, using R and the R package httr"
date:   2017-08-07
dateCreated:  2017-07-07
lastModified: `r format(Sys.time(), "%Y-%m-%d")`
estimatedTime: 1 - 1.5 hours
packagesLibraries: [httr, devtools, neonDataStackR]
authors: [Claire K. Lunch]
contributors: [Claire Lunch, Christine Laney, Megan A. Jones]
categories: [self-paced-tutorial]
mainTag: API
tags: [R, API]
code1: 
image:
  feature:
  credit:
  creditlink:
permalink: /R/neon-api/
comments: false
---

{% include _toc.html %}

## About
This is a lesson in pulling data from the NEON API, using base R 
and the R package httr. There are 3 basic categories of NEON data:

1. Observational - Data collected by a human in the field, or in an analytical laboratory, e.g. beetle identification, foliar isotopes
1. Instrumentation - Data collected by an automated, streaming sensor, e.g. net radiation, soil carbon dioxide
1. Remote sensing - Data collected by the airborne observation platform, e.g. LIDAR, surface reflectance

This lesson covers the first two types of data. NEON remote sensing data are not currently available through the API.

**R Skill Level:** Intermediate - you've got the basics of `R` down.

**API Skill Level:** Beginner - you have little to no experience with APIs.

<div id="objectives" markdown="1">

# Goals / Objectives
After completing this activity, you will:

* Be able to pull observational, instrumentation, and geolocation data from the NEON API.
* Be able to transform API-accessed data from JSON to tabular format for analyses.

## Things Youâ€™ll Need To Complete This Tutorial
To complete this tutorial you will need the most current version of R and, 
preferably, RStudio loaded on your computer.

### Install R Packages

* **httr:** `install.packages("httr")`
* **jsonlite:** `install.packages("jsonlite")`
* **dplyr:** `install.packages("dplyr")`
* **devtools:** `install.packages("devtools")`
* **neonDataStackR:** `devtools::install_github("NEONScience/NEON-utilities/neonDataStackR")`

### Additional Resources

* [Website for the NEON API](http://data.neonscience.org/data-api)
* [GitHub repository for the NEON API](https://github.com/NEONScience/neon-data-api)
* [ROpenSci wrapper for the NEON API](https://github.com/ropenscilabs/nneo) (not covered in this tutorial)

</div>

## Anatomy of an API call
### Base URL: 
Specifics are appended to this in order to get the data or 
metadata you're looking for, but all calls to this API will include 
the base URL. For the NEON API, this is http://data.neonscience.org/api/v0 
(not clickable, because the base URL by itself will take you nowhere!)

### Endpoints: 
What type of data or metadata are you looking for?

* **~/products**
  Information about one or all of NEON's data products

* **~/sites**
  Information about data availability at the site specified in the call

* **~/locations**
  Spatial data for the NEON locations specified in the call

* **~/data**
  Data! By product, site, and date (in monthly chunks).

### Targets:
The specific product, site, or location you want to get data for.


## Observational data
Which product do you want to get data for? Consult the <a href="http://data.neonscience.org/data-product-catalog" target="_blank">data product catalog</a>.

We'll pick Breeding landbird point counts, DP1.10003.001

First query the products endpoint of the API to find out which sites and dates have data available. 
The structure of the URL for the call is base/endpoint/DPID, where DPID is the numbered identifier 
for the data product:

``` {r os-avail-query}

library(httr)
library(jsonlite)
library(dplyr)
req <- GET("http://data.neonscience.org/api/v0/products/DP1.10003.001")

```

The object returned from the GET has many layers of information. Entering the name of 
the object gives you some basic information about what you downloaded. The content() 
function returns the contents in the form of a highly nested list. This is typical of 
JSON-formatted data returned by APIs:

``` {r os-query-contents}

req
req.content <- content(req, as="parsed")
req.content

```

To get a more accessible view of which sites have data for which months, you'll 
need to extract data from the nested list. There are a variety of ways to do this, 
in this tutorial we'll explore a couple of them. Here we'll use `fromJSON()`, in the 
jsonlite package, which doesn't fully flatten the nested list, but gets us the part 
we need. To use it, we need a text version of the content:

``` {r os-query-fromJSON}

req.text <- content(req, as="text")
avail <- fromJSON(req.text, simplifyDataFrame=T, flatten=T)
avail

```

The object contains keywords, general info about the data product, and 
references for documentation, as well as data availability, which is what we 
need to tell us what we can download. 

``` {r os-query-avail-data}

bird.urls <- unlist(avail$data$siteCodes$availableDataUrls)
bird.urls

```

These are the URLs showing us what files are available for each month where 
there are data. For simplicity, we'll only query one month now.

``` {r os-query-bird-data-urls}

brd <- GET(bird.urls[6])
brd.files <- fromJSON(content(brd, as="text"))
brd.files$data$files

```

And now we have the names of the data files available for this site and 
month, and URLs where we can get the data files themselves. We'll use 
the file names to pick which ones we want. To translate, available files for 
July 2015 at Woodworth are all of the following: 

* NEON.D09.WOOD.DP1.10003.001.2015-07.expanded.20170720T182547Z.zip
  + zip of all files in the expanded package
* NEON.D09.WOOD.DP1.10003.001.brd_countdata.2015-07.expanded.20170720T182547Z.csv
  + count data table, expanded package version: counts of birds at each point
* NEON.D09.WOOD.DP1.10003.001.brd_perpoint.2015-07.expanded.20170720T182547Z.csv
  + point data table, expanded package version: metadata at each observation point
* NEON.Bird Conservancy of the Rockies.brd_personnel.csv
  + personnel data table: accuracy scores for bird observers
* NEON.D09.WOOD.DP1.10003.001.2015-07.basic.20170720T182547Z.zip
  + zip of all files in the basic package
* NEON.D09.WOOD.DP1.10003.001.brd_countdata.2015-07.basic.20170720T182547Z.csv
  + count data table, basic package version: counts of birds at each point
* NEON.D09.WOOD.DP1.10003.001.brd_perpoint.2015-07.basic.20170720T182547Z.csv
  + point data table, basic package version: metadata at each observation point
* NEON.DP1.10003.001_readme.txt
  + readme for the data product (not specific to dates or location)
  + appears twice in the list, since it's in both the basic and expanded package
* NEON.D09.WOOD.DP1.10003.001.20150101-20160613.xml
  + Ecological Metadata Language (EML) file
  + appears twice in the list, since it's in both the basic and expanded package
* NEON.D09.WOOD.DP0.10003.001.validation.20170720T182547Z.csv
  + validation file for the data product: lists input data and data entry rules
  + appears twice in the list, since it's in both the basic and expanded package
* NEON.D09.WOOD.DP1.10003.001.variables.20170720T182547Z.csv
  + variables file for the data product: lists data fields in downloaded tables
  + appears twice in the list, since it's in both the basic and expanded package


We'll get the data tables for the point data and count data in the basic 
package. The list of files doesn't return in the same order every time, so we 
won't use position in the list to select. Plus, we want code we can re-use 
when getting data from other sites and other months. So we select files 
based on the data table name and the package name:

``` {r os-get-bird-data}

brd.count <- read.delim(brd.files$data$files$url
                        [intersect(grep("countdata", brd.files$data$files$name),
                                    grep("basic", brd.files$data$files$name))], sep=",")

brd.point <- read.delim(brd.files$data$files$url
                        [intersect(grep("perpoint", brd.files$data$files$name),
                                    grep("basic", brd.files$data$files$name))], sep=",")

```

Just to prove the files we pulled have actual data in them, a quick graphic:

``` {r os-plot-bird-data}

clusterBySp <- brd.count %>% group_by(scientificName) %>% filter(plotID=="WOOD_013") %>%
  summarize(total=sum(clusterSize))
clusterBySp <- clusterBySp[order(clusterBySp$total, decreasing=T),]
barplot(clusterBySp$total, names.arg=clusterBySp$scientificName, ylab="Total")

```


## Instrumentation data
The process is essentially the same for sensor data. We'll do the same series of 
queries for Soil temperature, DP1.00041.001

``` {r soil-data}

req <- GET("http://data.neonscience.org/api/v0/products/DP1.00041.001")
avail <- fromJSON(content(req, as="text"), simplifyDataFrame=T, flatten=T)
temp.urls <- unlist(avail$data$siteCodes$availableDataUrls)
tmp <- GET(temp.urls[20])
tmp.files <- fromJSON(content(tmp, as="text"))
tmp.files$data$files$name

```

These are a little more cryptic. The part after the 00000 is: 
[soil plot number].[depth].[averaging interval].[data table name]

So NEON.D13.NIWO.DP1.00041.001.00000.003.502.030.ST_30_minute.csv is 
the 30-minute mean of soil temperature at Niwot Ridge in soil plot 3, 
2nd depth below the surface.

Go get it:

``` {r os-get-soil-data}

soil.temp <- read.delim(tmp.files$data$files$url
                        [grep("003.502.030", tmp.files$data$files$name)], sep=",")

```

And again, a plot to show we've downloaded something with data in it:

``` {r os-plot-soil-data}

plot(soil.temp$soilTempMean~soil.temp$startDateTime, pch=".", xlab="Date", ylab="T")

```






